{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d19989-d493-4669-940d-d0177652b7d2",
   "metadata": {},
   "source": [
    "# ------------ TIM Python Client - KPI Driven Anomaly Detection ------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a84d41-ca72-4b76-917b-064024c7908a",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "221bbc6d-9a68-4e03-ac15-c2d16dca305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import plotly as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as splt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55ea509-bd02-4207-9bce-a319df1fe82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tim\n",
    "client = tim.Tim(email='',password='',server='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6112898b-2541-41bf-bed7-22b80390bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_tim_function(action,object_type,arguments=None):\n",
    "    functions = {\n",
    "        'list':{\n",
    "            'user_group':client.user_groups.list_user_group,\n",
    "            'workspace':client.workspaces.list_workspace,\n",
    "            'dataset':client.datasets.list_dataset,\n",
    "            'dataset_version':client.datasets.list_dataset_versions,\n",
    "            'use_case':client.use_cases.list_use_case,\n",
    "            'experiment':client.experiments.list_experiment\n",
    "        },\n",
    "        'create':{\n",
    "            'user_group':client.user_groups.create_user_group,\n",
    "            'workspace':client.workspaces.create_workspace,\n",
    "            'use_case':client.use_cases.create_use_case,\n",
    "            'experiment':client.experiments.create_experiment\n",
    "        }\n",
    "    }\n",
    "    response = functions[action][object_type](**arguments)\n",
    "    return response\n",
    "\n",
    "def create_tim_object_configuration(pipeline,object_type,parameters,name):\n",
    "    \n",
    "    if object_type=='user_group':\n",
    "        configuration = {\"name\": name,\"users\": [{\"id\": client.users.details_user()['id'],\"isOwner\": True}]}\n",
    "    if object_type=='workspace':\n",
    "        configuration = {\"name\": name,\"userGroup\": {\"id\": parameters['user_group_id']}}\n",
    "    if object_type=='dataset':\n",
    "        try:\n",
    "            versionName = pipeline['dataset_version']['name']\n",
    "        except:\n",
    "            versionName = 'initial upload'\n",
    "        configuration = {\"name\": name,\"workspace\": {\"id\": parameters['workspace_id']},\"versionName\":versionName}\n",
    "    if object_type=='dataset_version':\n",
    "        configuration = update_dataset_configuration = {\"versionName\": name}\n",
    "    if object_type=='use_case':\n",
    "        configuration = {\"name\": name,\"workspace\": {\"id\": parameters['workspace_id']},\"dataset\": {\"id\": parameters['dataset_id']}}\n",
    "    if object_type=='experiment':\n",
    "        configuration = {\"name\": name,\"useCase\": {\"id\": parameters['use_case_id']},\"type\": pipeline['experiment']['create']['type']}\n",
    "    return configuration\n",
    "\n",
    "def check_tim_object(pipeline,object_type,parameters):\n",
    "    try:\n",
    "        object_id = pipeline[object_type]['id']\n",
    "        print(object_type,'id available.')\n",
    "    except:\n",
    "        try:\n",
    "            object_name = pipeline[object_type]['name']\n",
    "            object_list = [f for f in call_tim_function('list',object_type,parameters) if f['name']==object_name]\n",
    "            tim_object = object_list[0]\n",
    "            object_id = tim_object['id']\n",
    "            print(object_type,'found by name.')\n",
    "        except:\n",
    "            try:\n",
    "                add_to_configuration = pipeline[object_type]['create']['configuration']\n",
    "                object_name = add_to_configuration['versionName'] if object_type == 'dataset_version' else add_to_configuration['name']\n",
    "                create_configuration = create_tim_object_configuration(pipeline,object_type,parameters,object_name)\n",
    "                object_configuration = {**add_to_configuration, **create_configuration}\n",
    "            except:\n",
    "                object_name = pipeline[object_type]['name'] \n",
    "                object_configuration = create_tim_object_configuration(pipeline,object_type,parameters,object_name)\n",
    "            if object_type == 'dataset':\n",
    "                tim_file = pipeline[object_type]['create']['file']\n",
    "                tim_upload = client.upload_dataset(\n",
    "                    dataset = tim_file,\n",
    "                    configuration = object_configuration,\n",
    "                    outputs = ['response'],\n",
    "                    status_poll = print,\n",
    "                    tries_left = 300\n",
    "                )\n",
    "                tim_object = tim_upload.response\n",
    "            elif object_type == 'dataset_version':\n",
    "                tim_file = pipeline[object_type]['create']['file']\n",
    "                tim_update = client.update_dataset(\n",
    "                    dataset_id = parameters['id'],\n",
    "                    dataset_version = tim_file,\n",
    "                    configuration = object_configuration,\n",
    "                    outputs = ['response'],\n",
    "                    status_poll = print,\n",
    "                    tries_left = 300\n",
    "                )\n",
    "                tim_object = tim_update.response['version']                \n",
    "            else:\n",
    "                tim_object = call_tim_function('create',object_type,{'configuration':object_configuration})\n",
    "            object_id = tim_object['id']\n",
    "            print(object_type,'created.')\n",
    "    return object_id\n",
    "\n",
    "def tim_pipeline_setup(pipeline):\n",
    "    try:\n",
    "        response = {'name':pipeline['name']}\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        user_group_id = check_tim_object(pipeline=pipeline,object_type='user_group',parameters={})\n",
    "        response['user_group'] = user_group_id\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        workspace_id = check_tim_object(pipeline=pipeline,object_type='workspace',parameters={'user_group_id':user_group_id})\n",
    "        response['workspace'] = workspace_id\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        dataset_id = check_tim_object(pipeline=pipeline,object_type='dataset',parameters={'workspace_id':workspace_id})\n",
    "        response['dataset'] = dataset_id\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        dataset_version_id = check_tim_object(pipeline=pipeline,object_type='dataset_version',parameters={'id':dataset_id})\n",
    "        response['dataset_version'] = dataset_version_id\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        use_case_id = check_tim_object(pipeline=pipeline,object_type='use_case',parameters={'workspace_id':workspace_id,'dataset_id':dataset_id})\n",
    "        response['use_case'] = use_case_id    \n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        experiment_id = check_tim_object(pipeline=pipeline,object_type='experiment',parameters={'use_case_id':use_case_id})\n",
    "        response['experiment'] = experiment_id   \n",
    "    except:\n",
    "        pass\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65411b4a-b72d-4686-bf51-d63a923e3a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "class parallel:\n",
    "    def run(requests,poll = True):\n",
    "        tasks = deepcopy(requests)\n",
    "        executor = ThreadPoolExecutor(max_workers=32)\n",
    "        futures = []\n",
    "\n",
    "        for i, task in enumerate(tasks):\n",
    "            if not isinstance(task, dict):  # type: ignore\n",
    "                raise ValueError(f'Request {i+1} must be a dict')\n",
    "\n",
    "            if 'func' not in task:\n",
    "                raise KeyError(f\"Request {i+1} must contain key 'func'\")\n",
    "\n",
    "            if 'args' in task and not isinstance(task['args'], list):\n",
    "                raise ValueError(f\"Property 'args' of request {i+1} must be of type list\")\n",
    "            elif 'args' not in task:\n",
    "                task['args'] = []\n",
    "\n",
    "            if 'kwargs' in task and not isinstance(task['kwargs'], dict):\n",
    "                raise ValueError(f\"Property 'kwargs' of request {i+1} must be of type dict\")\n",
    "            elif 'kwargs' not in task:\n",
    "                task['kwargs'] = {}\n",
    "\n",
    "        for task in tasks:\n",
    "            func = task['func']\n",
    "            args = task['args']\n",
    "            kwargs = task['kwargs']\n",
    "\n",
    "            futures.append(executor.submit(func, *args, **kwargs))  # type: ignore\n",
    "        count = 0\n",
    "        for future, task in zip(futures, tasks):\n",
    "            task['exception'] = None\n",
    "            task['return_value'] = None\n",
    "\n",
    "            if future.exception() is not None:\n",
    "                task['exception'] = future.exception()\n",
    "            else:\n",
    "                task['return_value'] = future.result()\n",
    "            if poll:\n",
    "                clear_output(wait=True)\n",
    "                count +=1\n",
    "                print(count,'/',len(futures))\n",
    "        return tasks\n",
    "    \n",
    "def poll_status(status_requests,nb_checks=100):\n",
    "    open_check = [1]\n",
    "    idx = 0\n",
    "    while (len(open_check)>0 and idx<nb_checks):\n",
    "        clear_output(wait=True)\n",
    "        status_response = parallel.run(status_requests,False)\n",
    "        status_jobs = [f['return_value'] for f in status_response]\n",
    "        open_check = list(set([f.get('status') for f in status_jobs]).intersection(['Registered','Queued','Running']))\n",
    "        value_counter = {}\n",
    "        for cl in status_jobs:\n",
    "            v = cl['status']\n",
    "            if v not in value_counter: value_counter[v] = 0\n",
    "            value_counter[v] += 1\n",
    "        idx += 1\n",
    "        progress = round(sum([a for a in [f.get('progress') for f in status_jobs] if a is not None])/len(status_jobs),2)\n",
    "        print('check status:',idx,value_counter,progress)\n",
    "        if len(open_check)>0: time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c42f5e7-f91b-49a2-b403-b82eeff02608",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08ababcd-91e6-4012-a9a0-0e8ffe70e310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Datetime', 'Output', 'AmbientHumidity', 'AmbientTemperature',\n",
      "       'M1_RawMaterial_1', 'M1_RawMaterial_2', 'M1_RawMaterial_3',\n",
      "       'M1_RawMaterial_4', 'M1_RawMaterialFeeder', 'M1_Zone1_Temperature',\n",
      "       'M1_Zone2_Temperature', 'M1_MotorAmperage', 'M1_MotorRPM',\n",
      "       'M1_MaterialPressure', 'M1_MaterialTemperature',\n",
      "       'M1_ExitZoneTemperature', 'M2_RawMaterial_1', 'M2_RawMaterial_2',\n",
      "       'M2_RawMaterial_3', 'M2_RawMaterial_4', 'M2_RawMaterialFeeder',\n",
      "       'M2_Zone1_Temperature', 'M2_Zone2_Temperature', 'M2_MotorAmperage',\n",
      "       'M2_MotorRPM', 'M2_MaterialPressure', 'M2_MaterialTemperature',\n",
      "       'M2_ExitZoneTemperature', 'M3_RawMaterial_1', 'M3_RawMaterial_2',\n",
      "       'M3_RawMaterial_3', 'M3_RawMaterial_4', 'M3_RawMaterialFeeder',\n",
      "       'M3_Zone1_Temperature', 'M3_Zone2_Temperature', 'M3_MotorAmperage',\n",
      "       'M3_MotorRPM', 'M3_MaterialPressure', 'M3_MaterialTemperature',\n",
      "       'M3_ExitZoneTemperature', 'Stage_1_Temperature1',\n",
      "       'Stage_1_Temperature2', 'Stage_1_Temperature3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "csv_df = pd.read_csv('production_line.csv')\n",
    "print(csv_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caac1929-9dfc-4ebf-85be-a39b212bd5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tim_dataset = csv_df.copy()\n",
    "timestamp = 'Datetime'\n",
    "target = 'Output'\n",
    "predictors = [s for s in list(tim_dataset.columns) if s not in [timestamp,target]]\n",
    "tim_dataset = tim_dataset[[timestamp,target]+predictors].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a587e-4f26-42fd-a47f-9545b70f76be",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_data = tim_dataset.copy()\n",
    "fig = splt.make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.02)\n",
    "fig.add_trace(go.Scatter(x=v_data[timestamp], y=v_data[target], name=target,connectgaps=True), row=1, col=1)\n",
    "for idx, p in enumerate(predictors): fig.add_trace(go.Scatter(x=v_data[timestamp], y=v_data[p], name=p,connectgaps=True), row=2, col=1)\n",
    "fig.update_layout(height=600, width=1200, title_text=\"Data visualization\")\n",
    "fig.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7229f9e-99c4-4ddc-b6a5-9f0ef7ad93dd",
   "metadata": {},
   "source": [
    "# 2. TIM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd37445-b36a-4c9c-a307-6c2cd3c5e893",
   "metadata": {},
   "source": [
    "## 2.1 Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "555ce558-fca0-43ca-9244-7c3f34332d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = len(tim_dataset)//10\n",
    "initial_upload_df = tim_dataset[:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "137a7683-8ce3-4754-ad42-d81f81ef834e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_group found by name.\n",
      "workspace found by name.\n",
      "{'status': 'Running', 'progress': 80.0, 'createdAt': '2023-10-18T11:54:25.217Z'}\n",
      "{'status': 'FinishedWithWarning', 'progress': 100.0, 'createdAt': '2023-10-18T11:54:25.217Z'}\n",
      "dataset created.\n",
      "use_case created.\n",
      "experiment created.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'pipeline_1',\n",
       " 'user_group': '4f2bbd5d-4b40-473f-9cae-7c03508ae11c',\n",
       " 'workspace': '7f5a354a-026e-431c-85e9-261ec543329c',\n",
       " 'dataset': 'b225034c-d0ce-475d-95aa-642300a75dd6',\n",
       " 'use_case': '46bc82a5-4fe0-4ec4-b018-fc66af8b5b8b',\n",
       " 'experiment': 'd76a6521-731b-4385-981e-40820793c881'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_dataset_configuration = {\n",
    "    # \"timestampColumn\": timestamp,\n",
    "    # \"groupKeys\": group_keys,\n",
    "    \"name\": \"production_line\"\n",
    "}\n",
    "# -----------------------------------------------------------------------------------------------------------------------\n",
    "user_group = {\n",
    "    # 'id':'135c50cd-e6ea-423e-ae2b-581564cb9cbc',\n",
    "    'name':'POV',\n",
    "    # 'create':{'configuration':create_user_group_configuration}\n",
    "}\n",
    "workspace = {\n",
    "    # 'id':'e3e34c8f-3864-4199-af4b-70366c6a79db',\n",
    "    'name':'Templates',\n",
    "    # 'create':{'configuration':create_workspace_configuration}\n",
    "}\n",
    "dataset = {\n",
    "    # 'id':'0c217702-6d7c-4349-9345-a5d8c9120881',\n",
    "    # 'name':upload_dataset_configuration['name'],\n",
    "    'create':{'configuration':upload_dataset_configuration,'file':initial_upload_df}\n",
    "}\n",
    "dataset_version = {\n",
    "    # 'id':'03ea3953-3956-4155-8ad8-f3c95daadd5f',\n",
    "    # 'name':'panel_data_demo',\n",
    "    # 'create':{'configuration':update_dataset_configuration,'file':tim_dataset.tail(28)}\n",
    "}\n",
    "use_case = {\n",
    "    # 'id':'3b8ad8ce-8516-4ed4-a9e7-e891ed5e176c',\n",
    "    'name':'tag_subselection',\n",
    "    # 'create':{'configuration':create_use_case_configuration}\n",
    "}\n",
    "experiment = {\n",
    "    # 'id':'bc82c706-be70-4726-8976-dbadf75e7385',\n",
    "    'name':'KPI Driven Anomaly Detection',\n",
    "    'create':{\n",
    "        # 'configuration':create_use_case_configuration,\n",
    "        'type':'AnomalyDetection'\n",
    "    }\n",
    "}\n",
    "# -----------------------------------------------------------------------------------------------------------------------\n",
    "pipeline_input = {\n",
    "    'name':'pipeline_1',\n",
    "    'user_group':user_group,\n",
    "    'workspace':workspace,\n",
    "    'dataset':dataset,\n",
    "    'dataset_version':dataset_version,\n",
    "    'use_case':use_case,\n",
    "    'experiment':experiment\n",
    "}\n",
    "# -----------------------------------------------------------------------------------------------------------------------\n",
    "pipeline_response = tim_pipeline_setup(pipeline=pipeline_input)\n",
    "pipeline_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "244ae9f4-1519-4c75-bda5-999caeb99f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = pipeline_response['dataset']\n",
    "use_case_id = pipeline_response['use_case']\n",
    "experiment_id = pipeline_response['experiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80bf749-a7b9-403c-b524-a3106149b1f8",
   "metadata": {},
   "source": [
    "## 2.2 Dataset Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a25f51a-34d0-4d30-8df5-92e931fde5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_dataset_configuration = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f9b3185-c91b-4f21-b6dc-2da8ab1f35e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Running', 'progress': 85.0, 'createdAt': '2023-10-18T11:55:00.812Z'}\n",
      "{'status': 'FinishedWithWarning', 'progress': 100.0, 'createdAt': '2023-10-18T11:55:00.812Z'}\n",
      "1\n",
      "{'status': 'Running', 'progress': 85.0, 'createdAt': '2023-10-18T11:55:05.079Z'}\n",
      "{'status': 'FinishedWithWarning', 'progress': 100.0, 'createdAt': '2023-10-18T11:55:05.079Z'}\n",
      "2\n",
      "{'status': 'Running', 'progress': 85.0, 'createdAt': '2023-10-18T11:55:09.296Z'}\n",
      "{'status': 'FinishedWithWarning', 'progress': 100.0, 'createdAt': '2023-10-18T11:55:09.296Z'}\n",
      "3\n",
      "{'status': 'Running', 'progress': 85.0, 'createdAt': '2023-10-18T11:55:13.479Z'}\n",
      "{'status': 'FinishedWithWarning', 'progress': 100.0, 'createdAt': '2023-10-18T11:55:13.479Z'}\n",
      "4\n",
      "{'status': 'Running', 'progress': 85.0, 'createdAt': '2023-10-18T11:55:17.602Z'}\n",
      "{'status': 'Finished', 'progress': 100.0, 'createdAt': '2023-10-18T11:55:17.602Z'}\n",
      "5\n",
      "{'status': 'Running', 'progress': 85.0, 'createdAt': '2023-10-18T11:55:21.666Z'}\n",
      "{'status': 'FinishedWithWarning', 'progress': 100.0, 'createdAt': '2023-10-18T11:55:21.666Z'}\n",
      "6\n",
      "{'status': 'Running', 'progress': 80.0, 'createdAt': '2023-10-18T11:55:25.930Z'}\n",
      "{'status': 'FinishedWithWarning', 'progress': 100.0, 'createdAt': '2023-10-18T11:55:25.930Z'}\n",
      "7\n",
      "{'status': 'Running', 'progress': 80.0, 'createdAt': '2023-10-18T11:55:29.958Z'}\n",
      "{'status': 'FinishedWithWarning', 'progress': 100.0, 'createdAt': '2023-10-18T11:55:29.958Z'}\n",
      "8\n",
      "{'status': 'Running', 'progress': 80.0, 'createdAt': '2023-10-18T11:55:33.541Z'}\n",
      "{'status': 'FinishedWithWarning', 'progress': 100.0, 'createdAt': '2023-10-18T11:55:33.541Z'}\n",
      "9\n",
      "{'status': 'Running', 'progress': 80.0, 'createdAt': '2023-10-18T11:55:37.012Z'}\n",
      "{'status': 'Finished', 'progress': 100.0, 'createdAt': '2023-10-18T11:55:37.012Z'}\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    dataset = tim_dataset[batch_size*i:batch_size*(i+1)]\n",
    "    response = client.extended_datasets.update_dataset(\n",
    "        dataset_id = dataset_id,\n",
    "        dataset_version = dataset,\n",
    "        configuration = update_dataset_configuration,\n",
    "        wait_to_finish = True,\n",
    "        outputs = [\n",
    "            'response',\n",
    "            # 'logs',\n",
    "            # 'details'\n",
    "        ],\n",
    "        status_poll = print,\n",
    "        tries_left = 300,\n",
    "    )\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42898763-f1a6-4300-b02b-2500537edf20",
   "metadata": {},
   "source": [
    "## 2.3 Subselection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88602e3-566b-4dfd-b11f-24620476885b",
   "metadata": {},
   "source": [
    "### 2.3.1 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50e022f1-8dc6-4bda-a245-2a52bbcfa9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Subselection model',\n",
       " 'useCase': {'id': '46bc82a5-4fe0-4ec4-b018-fc66af8b5b8b'},\n",
       " 'experiment': {'id': 'd76a6521-731b-4385-981e-40820793c881'},\n",
       " 'configuration': {'domainSpecifics': [{'perspective': 'Residual',\n",
       "    'sensitivity': 0,\n",
       "    'minSensitivity': 0,\n",
       "    'maxSensitivity': 0}],\n",
       "  'normalBehaviorModel': {'features': ['Identity']}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_build_kpi_model_configuration = {\n",
    "    \"name\": \"Subselection model\",\n",
    "    \"useCase\": {\"id\": use_case_id},\n",
    "    \"experiment\": {\"id\": experiment_id},\n",
    "    \"configuration\": {\n",
    "        \"domainSpecifics\": [\n",
    "            {\n",
    "                \"perspective\": \"Residual\",\n",
    "                \"sensitivity\": 0,\n",
    "                \"minSensitivity\": 0,\n",
    "                \"maxSensitivity\": 0\n",
    "            }\n",
    "        ],\n",
    "        \"normalBehaviorModel\": {\n",
    "#             \"useNormalBehaviorModel\": True,\n",
    "#             \"normalization\": True,\n",
    "#             \"maxModelComplexity\": 50,\n",
    "            \"features\": [\n",
    "                \"Identity\",\n",
    "            ],\n",
    "#             \"dailyCycle\": true,\n",
    "#             \"useKPIoffsets\": true,\n",
    "#             \"allowOffsets\": true,\n",
    "#             \"offsetLimit\": {\"type\": \"Explicit\",\"value\": 0}\n",
    "#         },\n",
    "#         \"anomalousBehaviorModel\": {\n",
    "#             \"maxModelComplexity\": 15,\n",
    "#             \"detectionIntervals\": [\n",
    "#                 {\"type\": \"Hour\",\"value\": \"8-16\"}\n",
    "#             ]\n",
    "        }\n",
    "    },\n",
    "    # \"data\": {\n",
    "#         \"version\": {\"id\": \"a74ae716-a86e-47f0-8a50-d8b21d6d7dd6\"},\n",
    "        # \"rows\": {\"type\":\"First\",\"baseUnit\": \"Sample\",\"value\": in_sample_rows}, #{\"type\":\"Last\",\"baseUnit\": \"Sample\",\"value\": 1} or [{\"from\": \"yyyy-mm-dd HH:MM:SS\",\"to\": \"yyyy-mm-dd HH:MM:SS\"}]\n",
    "#         \"columns\": [\n",
    "#             1,\n",
    "#             3,\n",
    "#             \"wind_speed\"\n",
    "#         ],\n",
    "#         \"KPIColumn\": \"rotor_speed\",\n",
    "#         \"holidayColumn\": \"PH\",\n",
    "#         \"labelColumn\": \"LABEL\",\n",
    "#         \"imputation\": {\"type\": \"LOCF\",\"maxGapLength\": 6},\n",
    "#         \"timeScale\": {\"baseUnit\": \"Hour\",\"value\": 1},\n",
    "#         \"aggregation\": \"Mean\",\n",
    "#         \"updates\": [\n",
    "#             {\n",
    "#                 \"column\": \"wind_speed\",\n",
    "#                 \"updateTime\": [\n",
    "#                     {\"type\": \"Hour\",\"value\": \"1,12,23\"}\n",
    "#                 ],\n",
    "#                 \"updateUntil\": {\"baseUnit\": \"Hour\",\"offset\": -2}\n",
    "#             }\n",
    "#         ]\n",
    "    # }\n",
    "}\n",
    "detection_build_kpi_model_configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ec89f6-03a0-4be6-951d-1c2fba34d784",
   "metadata": {},
   "source": [
    "### 2.2.2 API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4276ad6-4b75-4d0b-952e-52431e64b6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Running', 'progress': 6.5, 'CPU': 0.11, 'memory': 4209.0, 'createdAt': '2023-10-18T11:57:19.528Z'}\n",
      "{'status': 'Running', 'progress': 60.0, 'CPU': 0.11, 'memory': 4203.0, 'createdAt': '2023-10-18T11:57:20.847Z'}\n",
      "{'status': 'Running', 'progress': 60.0, 'CPU': 0.11, 'memory': 4203.0, 'createdAt': '2023-10-18T11:57:20.847Z'}\n",
      "{'status': 'Running', 'progress': 100.0, 'CPU': 0.27, 'memory': 4217.0, 'createdAt': '2023-10-18T11:57:26.738Z'}\n",
      "{'status': 'Finished', 'progress': 100.0, 'CPU': 0.27, 'memory': 4217.0, 'createdAt': '2023-10-18T11:57:26.738Z'}\n"
     ]
    }
   ],
   "source": [
    "detection_build_kpi_model = client.detection_build_kpi_model(\n",
    "    configuration = detection_build_kpi_model_configuration,\n",
    "    # dataset_id = dataset_id,\n",
    "    # execute = True,\n",
    "    # wait_to_finish = True,\n",
    "    outputs = [\n",
    "        'id',\n",
    "        'details',\n",
    "        'logs',\n",
    "        'status',\n",
    "        'table',\n",
    "        'model',\n",
    "        'accuracies'\n",
    "    ],\n",
    "    status_poll = print,\n",
    "    # tries_left = 300\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "334bb6f7-570e-4bab-b28c-43a0dac3221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_build_kpi_model_id = detection_build_kpi_model.id\n",
    "detection_build_kpi_model_details = detection_build_kpi_model.details\n",
    "detection_build_kpi_model_logs = detection_build_kpi_model.logs\n",
    "detection_build_kpi_model_status = detection_build_kpi_model.status\n",
    "detection_build_kpi_model_table = detection_build_kpi_model.table\n",
    "detection_build_kpi_model_model = detection_build_kpi_model.model\n",
    "detection_build_kpi_model_accuracies = detection_build_kpi_model.accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720074de-6bb7-442f-8c9f-70cfeea9ae9e",
   "metadata": {},
   "source": [
    "# 3. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "045bc035-675e-4b9b-9bbe-1df36da08dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_df = client.post_process.properties(detection_build_kpi_model_model)\n",
    "features_df = client.post_process.features(detection_build_kpi_model_model)\n",
    "model_logs_df = pd.DataFrame(detection_build_kpi_model_logs).sort_values(by='createdAt').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d59f8e9-df43-4b67-b7bd-617899e5f3f2",
   "metadata": {},
   "source": [
    "## 3.1 Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cb30eb-b8aa-4a63-b7ae-210203ba0865",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = splt.make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.02)\n",
    "fig.add_trace(go.Scatter(x=tim_dataset[timestamp], y=tim_dataset[target], name=target, line=dict(color='black')), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=detection_build_kpi_model_table['timestamp'], y=detection_build_kpi_model_table['normal_behavior'], name='InSample Normal Behavior', line=dict(color='goldenrod')), row=1, col=1)\n",
    "for ai in [f for f in detection_build_kpi_model_table.columns if 'anomaly_indicator' in f]:\n",
    "    fig.add_trace(go.Scatter(x=detection_build_kpi_model_table['timestamp'], y=detection_build_kpi_model_table[ai], name= ai.replace('anomaly_indicator_','')+' InSample'), row=2, col=1)\n",
    "    va = detection_build_kpi_model_table[detection_build_kpi_model_table[ai]>=1]\n",
    "    fig.add_trace(go.Scatter(x=va['timestamp'], y=va['kpi'], name=ai.replace('anomaly_indicator_','')+' anomaly inSample',mode='markers', line={'color': 'red'}), row=1, col=1)\n",
    "fig.add_hline(y=1, line_color=\"orange\", row=2, col=1)\n",
    "fig.update_layout(height=700, width=1400, title_text=\"Results\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe3e75f-a7a0-4ff3-b966-ee597259d2a0",
   "metadata": {},
   "source": [
    "## 3.3 Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff55de4c-1c31-476b-9e6a-e299a06d6116",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = go.Figure(go.Bar(x=properties_df['name'], y=properties_df['rel_importance'],text=round(properties_df['rel_importance'],2),textposition='auto'))\n",
    "fig1.update_layout(height=500,width=1200,title_text='Predictor Importances',xaxis_title='name',yaxis_title='rel_importance')\n",
    "print('Predictors not used:'+str(list(set(predictors+[target])-set(list(properties_df['name'])))))\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95644853-dd16-47d9-801a-87d2ea4654d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.sunburst(features_df, path=['Model','Feature'], values='importance',color='Feature')\n",
    "fig.update_layout(height=700,width=700,title_text='Feature Importances')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a649fb7-b8f6-4af6-a6e1-d2c0294cb229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings = list(model_logs_df[model_logs_df['messageType'] == \"Warning\"]['message'])\n",
    "warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d530ba1e-a502-4366-a66f-3d74132eea4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>messageType</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The job is categorized as light.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-10-18T11:57:18.090Z</td>\n",
       "      <td>Registration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Expected result table size is 1.3 MiB.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-10-18T11:57:18.090Z</td>\n",
       "      <td>Registration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Job waiting in the queue mlJobs_Light with pri...</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-10-18T11:57:18.837Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Executing job.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-10-18T11:57:18.910Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Detection job, type: model building, approach:...</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-10-18T11:57:18.941Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Getting data from dataset version \"4c153b7f-f3...</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-10-18T11:57:18.968Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Used sampling period 1 second.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-10-18T11:57:19.457Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Validation successful.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-10-18T11:57:19.513Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Building the normal behavior model.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-10-18T11:57:19.524Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Parameter useKPIoffsets is set to true. Reason...</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-10-18T11:57:19.562Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TIM will consider this dataset to be nondaily-...</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-10-18T11:57:19.571Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Offset limit set to -1.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-10-18T11:57:19.997Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Building the anomalous behavior model.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-10-18T11:57:20.648Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Creating anomaly detection results.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-10-18T11:57:26.608Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Saving results.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-10-18T11:57:26.755Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Table result saved. Size of the stored data is...</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-10-18T11:57:27.002Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Model saved. Size of the stored data is 33124 ...</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-10-18T11:57:27.066Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Execution finished.</td>\n",
       "      <td>Info</td>\n",
       "      <td>2023-10-18T11:57:27.838Z</td>\n",
       "      <td>Execution</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              message messageType  \\\n",
       "0                    The job is categorized as light.        Info   \n",
       "1              Expected result table size is 1.3 MiB.        Info   \n",
       "2   Job waiting in the queue mlJobs_Light with pri...        Info   \n",
       "3                                      Executing job.        Info   \n",
       "4   Detection job, type: model building, approach:...        Info   \n",
       "5   Getting data from dataset version \"4c153b7f-f3...        Info   \n",
       "6                      Used sampling period 1 second.        Info   \n",
       "7                              Validation successful.        Info   \n",
       "8                 Building the normal behavior model.        Info   \n",
       "9   Parameter useKPIoffsets is set to true. Reason...        Info   \n",
       "10  TIM will consider this dataset to be nondaily-...        Info   \n",
       "11                            Offset limit set to -1.        Info   \n",
       "12             Building the anomalous behavior model.        Info   \n",
       "13                Creating anomaly detection results.        Info   \n",
       "14                                    Saving results.        Info   \n",
       "15  Table result saved. Size of the stored data is...        Info   \n",
       "16  Model saved. Size of the stored data is 33124 ...        Info   \n",
       "17                                Execution finished.        Info   \n",
       "\n",
       "                   createdAt        origin  \n",
       "0   2023-10-18T11:57:18.090Z  Registration  \n",
       "1   2023-10-18T11:57:18.090Z  Registration  \n",
       "2   2023-10-18T11:57:18.837Z     Execution  \n",
       "3   2023-10-18T11:57:18.910Z     Execution  \n",
       "4   2023-10-18T11:57:18.941Z     Execution  \n",
       "5   2023-10-18T11:57:18.968Z     Execution  \n",
       "6   2023-10-18T11:57:19.457Z     Execution  \n",
       "7   2023-10-18T11:57:19.513Z     Execution  \n",
       "8   2023-10-18T11:57:19.524Z     Execution  \n",
       "9   2023-10-18T11:57:19.562Z     Execution  \n",
       "10  2023-10-18T11:57:19.571Z     Execution  \n",
       "11  2023-10-18T11:57:19.997Z     Execution  \n",
       "12  2023-10-18T11:57:20.648Z     Execution  \n",
       "13  2023-10-18T11:57:26.608Z     Execution  \n",
       "14  2023-10-18T11:57:26.755Z     Execution  \n",
       "15  2023-10-18T11:57:27.002Z     Execution  \n",
       "16  2023-10-18T11:57:27.066Z     Execution  \n",
       "17  2023-10-18T11:57:27.838Z     Execution  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2111cfde-9462-46f6-990c-14ccafbf5bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
